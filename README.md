# Low-Code Deep Learning Platform
ä½ä»£ç æ·±åº¦å­¦ä¹ å¹³å°

## é¡¹ç›®æ¦‚è¿° (Project Overview)

è¿™æ˜¯ä¸€ä¸ªä¸“ä¸ºç§‘å­¦è®¡ç®—å’Œå·¥ç¨‹åº”ç”¨è®¾è®¡çš„ä½ä»£ç æ·±åº¦å­¦ä¹ å¹³å°ï¼Œæ”¯æŒå¤šç§å…ˆè¿›ç¥ç»ç½‘ç»œæ¶æ„ï¼ŒåŒ…æ‹¬FNOã€UNetã€Transformerã€Transolverå’ŒMeshGraphNetç­‰æ¨¡å‹ã€‚å¹³å°é‡‡ç”¨æ¨¡å—åŒ–è®¾è®¡ï¼Œé€šè¿‡é…ç½®æ–‡ä»¶é©±åŠ¨æ•´ä¸ªè®­ç»ƒå’Œæ¨ç†æµç¨‹ã€‚

This is a low-code deep learning platform designed specifically for scientific computing and engineering applications, supporting advanced neural network architectures including FNO, UNet, Transformer, Transolver, and MeshGraphNet models. The platform features a modular design driven entirely by configuration files.

## æ ¸å¿ƒç‰¹æ€§ (Core Features)

### ğŸ§  æ”¯æŒçš„æ¨¡å‹æ¶æ„ (Supported Model Architectures)
- **FNO (Fourier Neural Operator)** - ç”¨äºPDEæ±‚è§£çš„å‚…é‡Œå¶ç¥ç»ç®—å­
- **UNet** - ç»å…¸çš„å›¾åƒåˆ†å‰²å’Œå›å½’ç½‘ç»œ
- **Transformer** - æ³¨æ„åŠ›æœºåˆ¶æ¨¡å‹
- **Transolver** - ç§‘å­¦è®¡ç®—ä¸“ç”¨Transformerå˜ä½“
- **MeshGraphNet** - åŸºäºå›¾ç¥ç»ç½‘ç»œçš„ç½‘æ ¼å¤„ç†æ¨¡å‹
- **MLP** - å¤šå±‚æ„ŸçŸ¥æœº

### ğŸ“Š æ•°æ®å¤„ç†ç³»ç»Ÿ (Data Processing System)
- **å¤šæºæ•°æ®æ”¯æŒ** - æ”¯æŒå¤šä¸ªè¾“å…¥æ•°æ®æºçš„å¹¶è¡Œå¤„ç†
- **å¤šç§æ•°æ®æ ¼å¼** - CSVã€JSONã€NPYã€NPZæ ¼å¼æ”¯æŒ
- **æ™ºèƒ½æ•°æ®æ ‡å‡†åŒ–** - æ”¯æŒStandardã€MinMaxã€Robustæ ‡å‡†åŒ–æ–¹æ³•
- **åŠ¨æ€æ•°æ®éªŒè¯** - è¿è¡Œæ—¶æ•°æ®ä¸€è‡´æ€§æ£€æŸ¥

### âš™ï¸ è®­ç»ƒå¼•æ“ (Training Engine)
- **å¤šä¼˜åŒ–å™¨æ”¯æŒ** - Adamã€SGDã€AdamWç­‰ä¸»æµä¼˜åŒ–å™¨
- **ä¸°å¯ŒæŸå¤±å‡½æ•°** - CrossEntropyã€MSEã€L1ã€BCEç­‰å¤šç§æŸå¤±å‡½æ•°
- **å­¦ä¹ ç‡è°ƒåº¦** - Stepã€Exponentialã€CosineAnnealingè°ƒåº¦å™¨
- **è‡ªå®šä¹‰é¢„å¤„ç†** - æ”¯æŒPythonæ–‡ä»¶è‡ªå®šä¹‰æ•°æ®é¢„å¤„ç†å‡½æ•°
- **GPU/CPUè‡ªåŠ¨é€‚é…** - æ™ºèƒ½è®¾å¤‡é€‰æ‹©å’Œå†…å­˜ç®¡ç†

## å¿«é€Ÿå¼€å§‹ (Quick Start)

### ç¯å¢ƒè¦æ±‚ (Requirements)
```bash
Python 3.8+
PyTorch 1.9+
numpy
pandas
scikit-learn
pyyaml
```

### å®‰è£…æ­¥éª¤ (Installation)

1. **å…‹éš†é¡¹ç›®**
   ```bash
   git clone <repository-url>
   cd deeplearning-platform
   ```

2. **å®‰è£…ä¾èµ–**
   ```bash
   pip install -r requirements.txt
   ```

3. **è¿è¡Œè®­ç»ƒ**
   ```bash
   python main/train.py --config configs/example_config.yaml
   ```

### é…ç½®æ–‡ä»¶ç¤ºä¾‹ (Configuration Example)

åˆ›å»ºé…ç½®æ–‡ä»¶ `configs/my_training.yaml`:

```yaml
# æ•°æ®é…ç½® (Data Configuration)
data:
  train_features_path: "data/train_X.csv"
  train_targets_path: "data/train_y.csv"
  test_features_path: "data/test_X.csv"
  test_targets_path: "data/test_y.csv"
  batch_size: 64
  shuffle: true
  normalize: true
  normalization_method: "standard"

# æ¨¡å‹é…ç½® (Model Configuration)
model:
  name: "fno"
  parameters:
    in_channels: 3
    out_channels: 1
    modes: 12
    width: 32

# è®­ç»ƒé…ç½® (Training Configuration)
training:
  epochs: 100
  device: "cuda"  # or "cpu"

# ä¼˜åŒ–å™¨é…ç½® (Optimizer Configuration)
optimizer:
  name: "adam"
  parameters:
    lr: 0.001
    weight_decay: 1e-4

# æŸå¤±å‡½æ•°é…ç½® (Criterion Configuration)
criterion:
  name: "mse"

# å­¦ä¹ ç‡è°ƒåº¦å™¨é…ç½® (Scheduler Configuration)
scheduler:
  name: "step"
  parameters:
    step_size: 30
    gamma: 0.1

# è¾“å‡ºé…ç½® (Output Configuration)
output:
  model_path: "models/trained_model.pth"
  history_path: "results/training_history.json"
```

## å¤šæºæ•°æ®å¤„ç† (Multi-Source Data Processing)

å¹³å°æ”¯æŒåŒæ—¶å¤„ç†å¤šä¸ªè¾“å…¥æ•°æ®æºï¼Œé€‚ç”¨äºå¤æ‚çš„å¤šæ¨¡æ€å­¦ä¹ åœºæ™¯ï¼š

```yaml
data:
  train_features_paths:
    pressure: "data/train_pressure.csv"
    velocity: "data/train_velocity.csv"
    temperature: "data/train_temp.csv"
  train_targets_path: "data/train_solution.csv"
  test_features_paths:
    pressure: "data/test_pressure.csv"
    velocity: "data/test_velocity.csv"
    temperature: "data/test_temp.csv"
  test_targets_path: "data/test_solution.csv"
```

## é¡¹ç›®ç»“æ„ (Project Structure)

```
deeplearning-platform/
â”œâ”€â”€ main/
â”‚   â””â”€â”€ train.py                 # ä¸»è®­ç»ƒè„šæœ¬
â”œâ”€â”€ data_loader/
â”‚   â””â”€â”€ src/
â”‚       â””â”€â”€ data_loader.py       # æ•°æ®åŠ è½½å’Œå¤„ç†æ¨¡å—
â”œâ”€â”€ model_architecture/
â”‚   â””â”€â”€ src/
â”‚       â””â”€â”€ model_manager.py     # æ¨¡å‹ç®¡ç†å’Œæ³¨å†Œç³»ç»Ÿ
â”œâ”€â”€ training_engine/
â”‚   â””â”€â”€ src/
â”‚       â””â”€â”€ training_engine.py   # è®­ç»ƒå¼•æ“æ ¸å¿ƒ
â”œâ”€â”€ configs/                     # é…ç½®æ–‡ä»¶ç›®å½•
â”œâ”€â”€ data/                        # æ•°æ®æ–‡ä»¶ç›®å½•
â”œâ”€â”€ models/                      # è®­ç»ƒå¥½çš„æ¨¡å‹ä¿å­˜ç›®å½•
â”œâ”€â”€ results/                     # è®­ç»ƒç»“æœå’Œæ—¥å¿—ç›®å½•
â””â”€â”€ requirements.txt             # Pythonä¾èµ–åˆ—è¡¨
```

## æ¨¡å—è¯¦è§£ (Module Details)

### 1. æ•°æ®åŠ è½½æ¨¡å— (Data Loader Module)

**ä½ç½®**: `data_loader/src/data_loader.py`

**æ ¸å¿ƒåŠŸèƒ½**:
- `DataLoaderModule`: ä¸»æ•°æ®åŠ è½½ç±»ï¼Œæ”¯æŒå•æºå’Œå¤šæºæ•°æ®å¤„ç†
- `DataNormalizer`: æ•°æ®æ ‡å‡†åŒ–å·¥å…·ï¼Œæ”¯æŒå¤šç§æ ‡å‡†åŒ–æ–¹æ³•
- `MultiSourceDataset`: å¤šæºæ•°æ®é›†ç±»ï¼Œæ”¯æŒå¤æ‚è¾“å…¥ç»“æ„
- `BaseDataset`: åŸºç¡€æ•°æ®é›†ç±»ï¼Œå¤„ç†æ ‡å‡†æ•°æ®æ ¼å¼

**ä½¿ç”¨ç¤ºä¾‹**:
```python
from data_loader import DataLoaderModule

config = {
    "train_features_path": "data/train.csv",
    "test_features_path": "data/test.csv",
    "batch_size": 32,
    "normalize": True
}

data_loader = DataLoaderModule(config)
data_loader.prepare_datasets()
data_loader.create_data_loaders()
train_loader, test_loader = data_loader.get_data_loaders()
```

### 2. æ¨¡å‹ç®¡ç†æ¨¡å— (Model Manager)

**ä½ç½®**: `model_architecture/src/model_manager.py`

**æ ¸å¿ƒåŠŸèƒ½**:
- è‡ªåŠ¨æ¨¡å‹æ³¨å†Œå’Œå‘ç°
- æ¨¡å‹å‚æ•°éªŒè¯å’Œå®ä¾‹åŒ–
- æ”¯æŒè‡ªå®šä¹‰æ¨¡å‹æ‰©å±•
- æ¨¡å‹å…ƒæ•°æ®ç®¡ç†

**ä½¿ç”¨ç¤ºä¾‹**:
```python
from model_manager import ModelManager

manager = ModelManager({})
model = manager.create_model("fno", in_channels=3, out_channels=1, modes=12)
print(manager.list_models())  # æŸ¥çœ‹æ‰€æœ‰å¯ç”¨æ¨¡å‹
```

### 3. è®­ç»ƒå¼•æ“ (Training Engine)

**ä½ç½®**: `training_engine/src/training_engine.py`

**æ ¸å¿ƒåŠŸèƒ½**:
- å®Œæ•´çš„è®­ç»ƒå¾ªç¯ç®¡ç†
- è‡ªåŠ¨è®¾å¤‡é€‰æ‹©å’Œå†…å­˜ä¼˜åŒ–
- è®­ç»ƒå’ŒéªŒè¯æŒ‡æ ‡è·Ÿè¸ª
- æ¨¡å‹ä¿å­˜å’ŒåŠ è½½
- è‡ªå®šä¹‰é¢„å¤„ç†å‡½æ•°æ”¯æŒ

**ä½¿ç”¨ç¤ºä¾‹**:
```python
from training_engine import TrainingEngine

config = {"epochs": 100, "device": "cuda"}
trainer = TrainingEngine(config)
trainer.set_model(model)
trainer.configure_optimizer("adam", lr=0.001)
trainer.configure_criterion("mse")
history = trainer.train(train_loader, test_loader)
```

## é«˜çº§ç”¨æ³• (Advanced Usage)

### è‡ªå®šä¹‰æ¨¡å‹æ³¨å†Œ (Custom Model Registration)

```python
from model_manager import ModelManager

class MyCustomModel(nn.Module):
    def __init__(self, input_dim, hidden_dim, output_dim):
        super().__init__()
        self.layers = nn.Sequential(
            nn.Linear(input_dim, hidden_dim),
            nn.ReLU(),
            nn.Linear(hidden_dim, output_dim)
        )
    
    def forward(self, x):
        return self.layers(x)

# æ³¨å†Œè‡ªå®šä¹‰æ¨¡å‹
manager = ModelManager({})
manager.register_custom_model("mycustom", MyCustomModel)
model = manager.create_model("mycustom", input_dim=10, hidden_dim=64, output_dim=1)
```

### è‡ªå®šä¹‰é¢„å¤„ç†å‡½æ•° (Custom Preprocessing)

åˆ›å»º `my_preprocess.py`:
```python
def preprocess_fn(data):
    """è‡ªå®šä¹‰æ•°æ®é¢„å¤„ç†å‡½æ•°"""
    if isinstance(data, dict):
        # å¤„ç†å¤šæºæ•°æ®
        combined = torch.cat([data[key] for key in sorted(data.keys())], dim=1)
        return combined
    return data
```

åœ¨é…ç½®æ–‡ä»¶ä¸­ä½¿ç”¨:
```yaml
training:
  preprocess_fn: "my_preprocess.py"
```

### æ‰¹é‡å®éªŒé…ç½® (Batch Experiment Configuration)

ä½¿ç”¨JSON/YAMLé…ç½®æ–‡ä»¶ç®¡ç†å¤šä¸ªå®éªŒ:

```bash
# è¿è¡Œå¤šä¸ªé…ç½®å®éªŒ
for config in configs/experiments/*.yaml; do
    python main/train.py --config "$config"
done
```

## æ•…éšœæ’é™¤ (Troubleshooting)

### å¸¸è§é—®é¢˜ (Common Issues)

1. **CUDAå†…å­˜ä¸è¶³**
   ```yaml
   training:
     device: "cpu"  # åˆ‡æ¢åˆ°CPU
     batch_size: 16  # å‡å°æ‰¹æ¬¡å¤§å°
   ```

2. **æ¨¡å‹å¯¼å…¥é”™è¯¯**
   - ç¡®ä¿æ‰€æœ‰æ¨¡å‹æ–‡ä»¶åœ¨æ­£ç¡®çš„ç›®å½•ç»“æ„ä¸‹
   - æ£€æŸ¥æ¨¡å‹ç±»çš„è¶…å‚æ•°å®šä¹‰

3. **æ•°æ®æ ¼å¼ä¸åŒ¹é…**
   - ä½¿ç”¨`data_loader.get_dataset_info()`æ£€æŸ¥æ•°æ®ä¿¡æ¯
   - ç¡®è®¤è¾“å…¥è¾“å‡ºç»´åº¦ä¸æ¨¡å‹é…ç½®åŒ¹é…

### æ€§èƒ½ä¼˜åŒ–å»ºè®® (Performance Optimization)

1. **æ•°æ®åŠ è½½ä¼˜åŒ–**
   - ä½¿ç”¨`.npy`æ ¼å¼æ›¿ä»£CSVä»¥æé«˜åŠ è½½é€Ÿåº¦
   - å¯ç”¨æ•°æ®æ ‡å‡†åŒ–ç¼“å­˜

2. **è®­ç»ƒåŠ é€Ÿ**
   - ä½¿ç”¨GPUè®­ç»ƒ (`device: "cuda"`)
   - è°ƒæ•´æ‰¹æ¬¡å¤§å°ä»¥å¹³è¡¡å†…å­˜å’Œé€Ÿåº¦
   - ä½¿ç”¨æ··åˆç²¾åº¦è®­ç»ƒï¼ˆéœ€è¦ä»£ç æ‰©å±•ï¼‰

3. **å†…å­˜ç®¡ç†**
   - ç›‘æ§GPUå†…å­˜ä½¿ç”¨
   - ä½¿ç”¨æ¢¯åº¦ç´¯ç§¯å¤„ç†å¤§æ‰¹æ¬¡

## æ‰©å±•æŒ‡å— (Extension Guide)

### æ·»åŠ æ–°æ¨¡å‹æ¶æ„ (Adding New Model Architectures)

1. åœ¨å¯¹åº”ç›®å½•åˆ›å»ºæ¨¡å‹æ–‡ä»¶ï¼ˆå¦‚`fno/fno.py`ï¼‰
2. å®šä¹‰æ¨¡å‹ç±»å’ŒHYPERPARAMETERSé™æ€å˜é‡
3. æ¨¡å‹ä¼šè‡ªåŠ¨è¢«ModelManageræ³¨å†Œ

### æ·»åŠ æ–°æ•°æ®æ ¼å¼æ”¯æŒ (Adding New Data Format Support)

åœ¨`DataLoaderModule.load_data()`æ–¹æ³•ä¸­æ·»åŠ æ–°çš„æ–‡ä»¶æ ¼å¼å¤„ç†é€»è¾‘ã€‚

### æ·»åŠ æ–°ä¼˜åŒ–å™¨æˆ–æŸå¤±å‡½æ•° (Adding New Optimizers or Loss Functions)

åœ¨`TrainingEngine`ç±»ä¸­æ·»åŠ æ–°çš„ä¼˜åŒ–å™¨å’ŒæŸå¤±å‡½æ•°é…ç½®ã€‚

## è®¸å¯è¯ (License)

MIT License - æŸ¥çœ‹ [LICENSE](LICENSE) æ–‡ä»¶äº†è§£è¯¦æƒ…

## è´¡çŒ®æŒ‡å— (Contributing)

1. Forkæœ¬é¡¹ç›®
2. åˆ›å»ºåŠŸèƒ½åˆ†æ”¯ (`git checkout -b feature/AmazingFeature`)
3. æäº¤æ›´æ”¹ (`git commit -m 'Add some AmazingFeature'`)
4. æ¨é€åˆ°åˆ†æ”¯ (`git push origin feature/AmazingFeature`)
5. åˆ›å»ºPull Request

## æ”¯æŒä¸è”ç³» (Support & Contact)

- ğŸ“§ é—®é¢˜åé¦ˆï¼šæäº¤GitHub Issue
- ğŸ“– æ–‡æ¡£æ›´æ–°ï¼šæ¬¢è¿è´¡çŒ®æ–‡æ¡£æ”¹è¿›
- ğŸ’¡ åŠŸèƒ½å»ºè®®ï¼šé€šè¿‡Issueæˆ–Discussionæå‡º

---

*æœ€åæ›´æ–°ï¼š2025å¹´9æœˆ1æ—¥*