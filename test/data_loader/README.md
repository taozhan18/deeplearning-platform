# Data Loader Module Tests

## Overview

This directory contains tests for the data loader module, which is responsible for loading and preprocessing data for machine learning models. The tests cover various data formats, normalization methods, and multi-source data handling.

## Test Structure

```
test/data_loader/
├── test_data_loader.py          # Main data loader tests
├── test_custom_data_generator.py # Tests for custom data generator functionality
├── integration_test.py          # Integration tests
├── run_tests.py                 # Test runner script
└── README.md                    # This file
```

## Test Descriptions

### 1. Main Data Loader Tests (test_data_loader.py)
- Test data loading from various formats (CSV, JSON, NPY, NPZ)
- Test data normalization methods (StandardScaler, MinMaxScaler, RobustScaler)
- Test multi-source data handling
- Test PyTorch DataLoader integration

### 2. Custom Data Generator Tests (test_custom_data_generator.py)
- Test custom simulation runner implementation
- Test custom data extractor implementation
- Test integration with the generic data generation pipeline
- Verify that users can implement their own data generators

### 3. Integration Tests (integration_test.py)
- End-to-end tests for the entire data loading pipeline
- Test various data configurations and edge cases
- Test memory mapping functionality

## Running Tests

### Run All Tests
```bash
cd test/data_loader
python run_tests.py
```

### Run Individual Test Files
```bash
cd test/data_loader
python test_data_loader.py
python test_custom_data_generator.py
python integration_test.py
```

### Run with pytest
```bash
# Run all data loader tests
python -m pytest test/data_loader/ -v

# Run specific test file
python -m pytest test/data_loader/test_data_loader.py -v

# Run specific test function
python -m pytest test/data_loader/test_data_loader.py::test_data_loader_with_normalization -v
```

## Custom Data Generator Test Details

The custom data generator test (`test_custom_data_generator.py`) verifies that users can implement their own simulation runners and data extractors that work with the generic data generation framework.

### Components Tested

1. **CustomSimulationRunner**
   - Implements the `SimulationRunner` abstract base class
   - Generates synthetic data based on input parameters
   - Simulates running a computational simulation

2. **CustomDataExtractor**
   - Implements the `DataExtractor` abstract base class
   - Extracts data from simulation output files
   - Processes synthetic data generated by the custom simulation runner

3. **Generic Pipeline Integration**
   - Verifies that the generic pipeline can work with custom components
   - Tests parameter space sampling and dataset generation
   - Ensures the complete workflow functions correctly

### Test Workflow

1. Define custom simulation runner and data extractor classes
2. Configure the generic pipeline to use custom components
3. Define parameter space for synthetic data generation
4. Run the complete data generation pipeline
5. Verify that all components work together correctly
6. Check that output files are generated correctly

### Custom Component Implementation

Users can implement their own data generators by:

1. **Creating a Custom Simulation Runner**
   ```python
   from generic_data_generator import SimulationRunner
   
   class MySimulationRunner(SimulationRunner):
       def run_simulation(self, input_file, output_dir, parameters):
           # Implement simulation logic
           pass
   ```

2. **Creating a Custom Data Extractor**
   ```python
   from generic_data_generator import DataExtractor
   
   class MyDataExtractor(DataExtractor):
       def extract_data(self, file_path, parameters=None):
           # Implement data extraction logic
           pass
   ```

3. **Configuring the Pipeline**
   ```python
   config = {
       "solver": "custom",
       "solver_config": {
           "custom_solver_class": "my_module.MySimulationRunner"
       },
       "extractor": "custom",
       "extractor_config": {
           "custom_extractor_class": "my_module.MyDataExtractor"
       },
       # ... other configuration
   }
   
   pipeline = GenericDataGenerationPipeline(config)
   results = pipeline.run_pipeline()
   ```

## Test Data

The tests use synthetic data generated on-the-fly to avoid dependencies on external files. This ensures that tests can run in any environment without requiring specific data files.

## Adding New Tests

To add new tests:

1. Create a new test function following the existing patterns
2. Use descriptive function names prefixed with `test_`
3. Include clear assertions to verify expected behavior
4. Add the test to the appropriate test file or create a new one
5. Update this README if adding new test categories

## Troubleshooting

### Common Issues

1. **Import Errors**
   - Ensure the project root is in the Python path
   - Check that all required modules are installed

2. **File Path Issues**
   - Tests use temporary directories for file operations
   - All test files are automatically cleaned up after tests

3. **Performance Issues**
   - Some tests may take longer due to data generation
   - Use specific test functions for faster debugging

### Debugging Tips

1. Run individual test functions to isolate issues
2. Use print statements or logging for debugging
3. Check the temporary directories created during tests
4. Verify that all dependencies are correctly installed

---

*Last updated: 2025年9月3日*